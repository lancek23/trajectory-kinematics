{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file performs classification on the trips dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics = pd.read_feather('generated_data/reduced_kinematics.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following performs classification using a DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts labels in order from most to least trips for confusion matrix\n",
    "class_labels = np.array(kinematics['agent_name'].value_counts().index)\n",
    "\n",
    "# print('Num agents: ', len(df['Agent_ID'].unique()))\n",
    "# print()\n",
    "# print('Num trips: ', len(df))\n",
    "\n",
    "# print(df['agent_name'].value_counts())\n",
    "# print()\n",
    "\n",
    "df = kinematics.drop(columns=['Agent_ID', 'Start_time', 'End_time', 'modality'])\n",
    "df = df[[c for c in df if c not in ['agent_name']] + ['agent_name']]\n",
    "\n",
    "df = df.to_numpy()\n",
    "\n",
    "# columns: accuracy, ROC_AUC, F1 score\n",
    "stats = np.zeros((5, 3))\n",
    "\n",
    "# Cycle 5 folds\n",
    "kf = StratifiedKFold(shuffle=True)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df[:, :-1], df[:, -1])):\n",
    "    print('Fold number %d' % k)\n",
    "\n",
    "    # Divide data\n",
    "    train = np.vstack([df[i] for i in train_index])\n",
    "    train_X = train[:, :-1]\n",
    "    train_Y = train[:, -1]\n",
    "    test = np.vstack([df[i] for i in test_index])\n",
    "    test_X = test[:, :-1]\n",
    "    test_Y = test[:, -1]\n",
    "\n",
    "    # Create Decision Tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_X, train_Y)\n",
    "\n",
    "    acc = clf.score(test_X, test_Y)\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    stats[k][0] = acc\n",
    "\n",
    "    y_pred = clf.predict_proba(test_X)\n",
    "    auc = roc_auc_score(test_Y, y_pred, multi_class='ovr')\n",
    "    print('AUC: %.3f' % auc)\n",
    "    stats[k][1] = auc\n",
    "\n",
    "    y_pred = clf.predict(test_X)\n",
    "    f1 = f1_score(test_Y, y_pred, average='macro')\n",
    "    print('F1 Score: %.3f' % f1)\n",
    "    stats[k][2] = f1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    cf = confusion_matrix(test_Y, y_pred, labels=class_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=class_labels)\n",
    "    disp.plot(ax=ax)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    #plt.savefig('figures/dtree{}.pdf'.format(k), format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Average +- 1 std dev')\n",
    "print('Accuracy: %.3f +- %.3f' % (np.mean(stats[:, 0]), np.std(stats[:, 0])))\n",
    "print('AUC: %.3f +- %.3f' % (np.mean(stats[:, 1]), np.std(stats[:, 1])))\n",
    "print('F1 Score: %.3f +- %.3f' % (np.mean(stats[:, 2]), np.std(stats[:, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following performs classification using a Weighted Random Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly guesses a label, based on the proportion of the labels in the data\n",
    "def weighted_random_guess(data):\n",
    "    # Generate random index in the data\n",
    "    index = random.randint(0, len(data) - 1)\n",
    "    return data[index][-1]\n",
    "\n",
    "\n",
    "# Puts labels in order from most to least trips for confusion matrix\n",
    "class_labels = np.array(kinematics['agent_name'].value_counts().index)\n",
    "\n",
    "df = kinematics.drop(columns=['Agent_ID', 'Start_time', 'End_time', 'modality'])\n",
    "df = df[[c for c in df if c not in ['agent_name']] + ['agent_name']]\n",
    "\n",
    "df = df.to_numpy()\n",
    "\n",
    "stats = np.zeros((5, 3))\n",
    "\n",
    "# Cycle 5 folds\n",
    "kf = StratifiedKFold(shuffle=True)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df[:, :-1], df[:, -1])):\n",
    "    print('Fold number %d' % k)\n",
    "\n",
    "    # Divide data\n",
    "    train = np.vstack([df[i] for i in train_index])\n",
    "    train_X = train[:, :-1]\n",
    "    train_Y = train[:, -1]\n",
    "    test = np.vstack([df[i] for i in test_index])\n",
    "    test_X = test[:, :-1]\n",
    "    test_Y = test[:, -1]\n",
    "\n",
    "    # Create weighted random guesses\n",
    "    y_pred = []\n",
    "    for i in range(len(test_Y)):\n",
    "        y_pred.append(weighted_random_guess(df))\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    hits = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == test_Y[i]:\n",
    "            hits += 1\n",
    "    acc = hits / len(y_pred)\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    stats[k][0] = acc\n",
    "\n",
    "    # This is essentially a waste of time: ROC_AUC is always 0.5 for random guessing\n",
    "    y_pred_probs = np.zeros(shape=(len(test_Y), len(class_labels)))\n",
    "    for i in range(len(class_labels)):\n",
    "        y_pred_probs[:, i] = np.count_nonzero(df[:, -1] == class_labels[i]) / len(df)\n",
    "    auc = roc_auc_score(test_Y, y_pred_probs, multi_class='ovr')\n",
    "    print('AUC: %.3f' % auc)\n",
    "    stats[k][1] = auc\n",
    "\n",
    "    f1 = f1_score(test_Y, y_pred, average='macro')\n",
    "    print('F1 Score: %.3f' % f1)\n",
    "    stats[k][2] = f1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    cf = confusion_matrix(test_Y, y_pred, labels=class_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=class_labels)\n",
    "    disp.plot(ax=ax)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    #plt.savefig('figures/weighted{}.pdf'.format(k), format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Average +- 1 std dev')\n",
    "print('Accuracy: %.3f +- %.3f' % (np.mean(stats[:, 0]), np.std(stats[:, 0])))\n",
    "print('AUC: %.3f +- %.3f' % (np.mean(stats[:, 1]), np.std(stats[:, 1])))\n",
    "print('F1 Score: %.3f +- %.3f' % (np.mean(stats[:, 2]), np.std(stats[:, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following performs classification using a True Random Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts labels in order from most to least trips for confusion matrix\n",
    "class_labels = np.array(kinematics['agent_name'].value_counts().index)\n",
    "\n",
    "df = kinematics.drop(columns=['Agent_ID', 'Start_time', 'End_time', 'modality'])\n",
    "df = df[[c for c in df if c not in ['agent_name']] + ['agent_name']]\n",
    "\n",
    "df = df.to_numpy()\n",
    "\n",
    "stats = np.zeros((5, 3))\n",
    "\n",
    "# Cycle 5 folds\n",
    "kf = StratifiedKFold(shuffle=True)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df[:, :-1], df[:, -1])):\n",
    "    print('Fold number %d' % k)\n",
    "\n",
    "    # Divide data\n",
    "    train = np.vstack([df[i] for i in train_index])\n",
    "    train_X = train[:, :-1]\n",
    "    train_Y = train[:, -1]\n",
    "    test = np.vstack([df[i] for i in test_index])\n",
    "    test_X = test[:, :-1]\n",
    "    test_Y = test[:, -1]\n",
    "\n",
    "    # Create unweighted random guesses\n",
    "    y_pred = []\n",
    "    for i in range(len(test_Y)):\n",
    "        y_pred.append(class_labels[random.randint(0, len(class_labels) - 1)])\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    hits = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == test_Y[i]:\n",
    "            hits += 1\n",
    "    acc = hits / len(y_pred)\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    stats[k][0] = acc\n",
    "\n",
    "    # This is essentially a waste of time: ROC_AUC is always 0.5 for random guessing\n",
    "    y_pred_probs = np.zeros(shape=(len(test_Y), len(class_labels)))\n",
    "    for i in range(len(class_labels)):\n",
    "        y_pred_probs[:, i] = np.count_nonzero(df[:, -1] == class_labels[i]) / len(df)\n",
    "    auc = roc_auc_score(test_Y, y_pred_probs, multi_class='ovr')\n",
    "    print('AUC: %.3f' % auc)\n",
    "    stats[k][1] = auc\n",
    "\n",
    "    f1 = f1_score(test_Y, y_pred, average='macro')\n",
    "    print('F1 Score: %.3f' % f1)\n",
    "    stats[k][2] = f1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    cf = confusion_matrix(test_Y, y_pred, labels=class_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=class_labels)\n",
    "    disp.plot(ax=ax)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    #plt.savefig('figures/weighted{}.pdf'.format(k), format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Average +- 1 std dev')\n",
    "print('Accuracy: %.3f +- %.3f' % (np.mean(stats[:, 0]), np.std(stats[:, 0])))\n",
    "print('AUC: %.3f +- %.3f' % (np.mean(stats[:, 1]), np.std(stats[:, 1])))\n",
    "print('F1 Score: %.3f +- %.3f' % (np.mean(stats[:, 2]), np.std(stats[:, 2])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expeditionenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
